{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trabajo práctico 2\n",
        "### Alumnos: Francisco Frusto Alvarado, Ezequiel Kaplan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Yc_QGcPrvhgj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "wpp8zX0evhgn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([[0.48631474, 0.35667743, 0.06265077, 0.59212344, 0.97536497,\n",
            "         0.50838568],\n",
            "        [0.74135631, 0.24650511, 0.23600963, 0.90830446, 0.59812068,\n",
            "         0.19029676],\n",
            "        [0.74978488, 0.16930195, 0.12280759, 0.60550947, 0.38565293,\n",
            "         0.77175354],\n",
            "        [0.07067545, 0.07115243, 0.56132013, 0.25055902, 0.10209022,\n",
            "         0.27460743],\n",
            "        [0.86342984, 0.99726788, 0.36099777, 0.16570482, 0.10845809,\n",
            "         0.13659808]])\n",
            " array([[0.09879222],\n",
            "        [0.79837635],\n",
            "        [0.44234104],\n",
            "        [0.29710498],\n",
            "        [0.48176168]])\n",
            " array([[0.21349149, 0.37504701, 0.66428418, 0.77375554, 0.46930586]])\n",
            " array([[0.66422576]])]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5d/4g206gss6cg3fktfbycqnb540000gn/T/ipykernel_27631/3391380950.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  theta = np.array([W1, b1, W2, b2])\n"
          ]
        }
      ],
      "source": [
        "#Inicializacion de pesos\n",
        "W1 = np.random.random((5,6))\n",
        "b1 = np.random.random((5,1))\n",
        "\n",
        "W2 = np.random.random((1,5))\n",
        "b2 = np.random.random((1,1))\n",
        "\n",
        "theta = np.array([W1, b1, W2, b2])\n",
        "print(theta)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para implementar la funcion forward, vamos a hacer los cálculos de a pasos, sabiendo:\n",
        "\n",
        "$\\newline f_{\\theta}(\\mathrm{\\mathbf{x}}) = W_{2} \\ \\sigma (W_{1} \\mathrm{\\mathbf{x}} + b_{1}) + b{2} $\n",
        "\n",
        "En una primera instancia calculamos $ z_{1} = W_{1} \\mathrm{\\mathbf{x}} + b_{1}$ en la que hacemos el producto punto entre $\\mathrm{\\mathbf{x}}$ y $W_{1}$ y luego le sumamos el vector $b_{1}$. \n",
        "\n",
        "En un segundo paso, habiendo creado la funcion sigmoid que calcula: $\\sigma(x) = \\frac{1}{1 + e^{-x}}$ vamos a aplicarle esta funcion a los elementos de $z_{1}$\n",
        "\n",
        "En un tercer paso, calculamos el resultado final en el que se hace el producto punto entre $W_{2}$ y el resultado anterior y ademas, se le suma el vector $b_{2}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def forward(theta, x):\n",
        "    W1, b1, W2, b2 = theta\n",
        "\n",
        "    z1 = np.dot(W1, x) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(W2, a1) + b2\n",
        "\n",
        "    return z2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La funcion obejtivo que buscamos minimizar, sabemos que está dada por: \n",
        "$\\newline L = \\frac{1}{2}(f_{\\theta_{t}}(\\mathrm{\\mathbf{x}}_{i}) - y_{i})^2$\n",
        "\n",
        "Para calcular el gradiente de forma numércia, vamos a usar la estrategia propuesta por la cátedra para calcular las derivadas parciales. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "P-R0FjEzvhgn"
      },
      "outputs": [],
      "source": [
        "#Calculo del gradiente numerico\n",
        "\n",
        "def funcion_objetivo(theta, x, y):\n",
        "    loss = 0.5 * (forward(theta, x) - y)**2\n",
        "    return loss\n",
        "\n",
        "def numerical_gradient(theta, x, y, eps):\n",
        "    epsilon = eps  # Pequeña cantidad para el cálculo numérico del gradiente\n",
        "    gradiente = np.zeros_like(theta)\n",
        "\n",
        "    for i in range(len(theta)):\n",
        "        theta_plus = theta.copy()\n",
        "        theta_minus = theta.copy()\n",
        "\n",
        "        # Aumentar y disminuir un poco el parámetro actual para calcular el gradiente\n",
        "        theta_plus[i] += epsilon\n",
        "        #print(f'el theta plus es: {theta_plus}')\n",
        "        theta_minus[i] -= epsilon\n",
        "        #print(f'el theta minus es: {theta_minus}')\n",
        "\n",
        "        # Calcular las pérdidas para los parámetros aumentados y disminuidos\n",
        "        loss_plus = funcion_objetivo(theta_plus, x, y)\n",
        "        print(f'el loss plus es: {loss_plus}')\n",
        "        loss_minus = funcion_objetivo(theta_minus, x, y)\n",
        "        print(f'el loss minus es: {loss_minus}')\n",
        "\n",
        "        # Calcular el gradiente parcial utilizando las derivadas parciales\n",
        "        gradiente[i] = (loss_plus - loss_minus) / (2 * epsilon)\n",
        "\n",
        "    print(f'el gradiente es: {gradiente}')\n",
        "    return gradiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "rJRtIYxMvhgo"
      },
      "outputs": [],
      "source": [
        "#funcion fit y loop de entrenamiento\n",
        "def fit(theta, x, y, learning_rate=0.001, epochs=1000):\n",
        "    TOLERANCIA = 0.0001\n",
        "    eps = 1e-5\n",
        "    loss_accum = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        loss_epoch = 0.0  # Pérdida acumulada en el epoch actual\n",
        "\n",
        "        for i in range(len(x)):\n",
        "            # Obtener el vector x y la salida esperada y correspondientes\n",
        "            x_i = x[i]\n",
        "            y_i = y[i]\n",
        "\n",
        "            # Calcular el gradiente numérico para el ejemplo actual\n",
        "            gradient = numerical_gradient(theta, x_i, y_i, eps)\n",
        "\n",
        "            # Transponer el gradiente para que tenga la forma (5, 1)\n",
        "            gradient = gradient.T\n",
        "\n",
        "            print(f'gradiente: {gradient}, theta: {theta}')\n",
        "\n",
        "            # Actualizar los parámetros\n",
        "            theta -= learning_rate * gradient\n",
        "\n",
        "            # Calcular la pérdida para el ejemplo actual\n",
        "            loss_i = funcion_objetivo(theta, x_i, y_i)\n",
        "            loss_epoch += loss_i\n",
        "\n",
        "        # Calcular la pérdida promedio para el epoch actual\n",
        "        loss_avg = loss_epoch / len(x)\n",
        "        loss_accum.append(loss_avg)\n",
        "\n",
        "        if abs(theta - loss_avg) < TOLERANCIA:\n",
        "            break\n",
        "\n",
        "    return loss_accum, theta\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "IS4sKd_Hvhgo"
      },
      "outputs": [],
      "source": [
        "def predict(x, theta):\n",
        "        y = np.dot(x, theta)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "el loss plus es: [[603.429984 603.429984 603.429984 603.429984 603.429984]]\n",
            "el loss minus es: [[603.429984 603.429984 603.429984 603.429984 603.429984]]\n",
            "el loss plus es: [[603.429984 603.429984 603.429984 603.429984 603.429984]]\n",
            "el loss minus es: [[603.429984 603.429984 603.429984 603.429984 603.429984]]\n",
            "el loss plus es: [[603.429984 603.429984 603.429984 603.429984 603.429984]]\n",
            "el loss minus es: [[603.429984 603.429984 603.429984 603.429984 603.429984]]\n",
            "el loss plus es: [[603.429984 603.429984 603.429984 603.429984 603.429984]]\n",
            "el loss minus es: [[603.429984 603.429984 603.429984 603.429984 603.429984]]\n",
            "el gradiente es: [array([[0., 0., 0., 0., 0.]]) array([[0., 0., 0., 0., 0.]])\n",
            " array([[0., 0., 0., 0., 0.]]) array([[0., 0., 0., 0., 0.]])]\n",
            "gradiente: [array([[0., 0., 0., 0., 0.]]) array([[0., 0., 0., 0., 0.]])\n",
            " array([[0., 0., 0., 0., 0.]]) array([[0., 0., 0., 0., 0.]])], theta: [array([[0.48631474, 0.35667743, 0.06265077, 0.59212344, 0.97536497,\n",
            "         0.50838568],\n",
            "        [0.74135631, 0.24650511, 0.23600963, 0.90830446, 0.59812068,\n",
            "         0.19029676],\n",
            "        [0.74978488, 0.16930195, 0.12280759, 0.60550947, 0.38565293,\n",
            "         0.77175354],\n",
            "        [0.07067545, 0.07115243, 0.56132013, 0.25055902, 0.10209022,\n",
            "         0.27460743],\n",
            "        [0.86342984, 0.99726788, 0.36099777, 0.16570482, 0.10845809,\n",
            "         0.13659808]])\n",
            " array([[0.09879222],\n",
            "        [0.79837635],\n",
            "        [0.44234104],\n",
            "        [0.29710498],\n",
            "        [0.48176168]])\n",
            " array([[0.21349149, 0.37504701, 0.66428418, 0.77375554, 0.46930586]])\n",
            " array([[0.66422576]])]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (5,6) (1,5) ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/5d/4g206gss6cg3fktfbycqnb540000gn/T/ipykernel_27631/1303780019.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mloss_accum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Obtener predicciones en el conjunto de datos de prueba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/var/folders/5d/4g206gss6cg3fktfbycqnb540000gn/T/ipykernel_27631/2758342087.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(theta, x, y, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Actualizar los parámetros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mtheta\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Calcular la pérdida para el ejemplo actual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5,6) (1,5) "
          ]
        }
      ],
      "source": [
        "# Entrenar la red neuronal\n",
        "df_test = pd.read_excel(\"datos.xlsx\", nrows=10)\n",
        "x = df_test.iloc[:, 1:7].values.tolist()\n",
        "y = df_test.iloc[:, 7].values.tolist()\n",
        "\n",
        "\n",
        "loss_accum, theta_new = fit(theta, x, y, learning_rate=0.001, epochs=1000)\n",
        "\n",
        "# Obtener predicciones en el conjunto de datos de prueba\n",
        "y_pred = predict(x, theta_new)\n",
        "\n",
        "# Calcular el error cuadrático medio en el conjunto de datos de prueba\n",
        "mse = ((y_pred - y) ** 2).mean()\n",
        "\n",
        "# Graficar la función objetivo a lo largo del entrenamiento\n",
        "plt.plot(loss_accum)\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Función Objetivo')\n",
        "plt.title('Evolución de la función objetivo durante el entrenamiento')\n",
        "plt.show()\n",
        "\n",
        "# Graficar el error cuadrático medio en el conjunto de datos de prueba\n",
        "plt.scatter(y, y_pred)\n",
        "plt.xlabel('Valor Real')\n",
        "plt.ylabel('Predicción')\n",
        "plt.title('Predicciones vs. Valores Reales en el conjunto de datos de prueba')\n",
        "plt.show()\n",
        "\n",
        "print(f'Error cuadrático medio en el conjunto de datos de prueba: {mse}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
