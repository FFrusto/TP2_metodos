{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trabajo práctico 2\n",
        "### Alumnos: Francisco Frusto Alvarado, Ezequiel Kaplan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Yc_QGcPrvhgj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "wpp8zX0evhgn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5d/4g206gss6cg3fktfbycqnb540000gn/T/ipykernel_27631/1755964871.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  theta = np.array([W1, b1, W2, b2])\n"
          ]
        }
      ],
      "source": [
        "#Inicializacion de pesos\n",
        "W1 = np.array(np.random.random((5,6)))\n",
        "b1 = np.array(np.random.random((5,1)))\n",
        "\n",
        "W2 = np.array(np.random.random((1,5)))\n",
        "b2 = np.array(np.random.random((1,1)))\n",
        "\n",
        "theta = np.array([W1, b1, W2, b2])\n",
        "print(theta)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para implementar la funcion forward, vamos a hacer los cálculos de a pasos, sabiendo:\n",
        "\n",
        "$\\newline f_{\\theta}(\\mathrm{\\mathbf{x}}) = W_{2} \\ \\sigma (W_{1} \\mathrm{\\mathbf{x}} + b_{1}) + b{2} $\n",
        "\n",
        "En una primera instancia calculamos $ z_{1} = W_{1} \\mathrm{\\mathbf{x}} + b_{1}$ en la que hacemos el producto punto entre $\\mathrm{\\mathbf{x}}$ y $W_{1}$ y luego le sumamos el vector $b_{1}$. \n",
        "\n",
        "En un segundo paso, habiendo creado la funcion sigmoid que calcula: $\\sigma(x) = \\frac{1}{1 + e^{-x}}$ vamos a aplicarle esta funcion a los elementos de $z_{1}$\n",
        "\n",
        "En un tercer paso, calculamos el resultado final en el que se hace el producto punto entre $W_{2}$ y el resultado anterior y ademas, se le suma el vector $b_{2}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def forward(theta, x):\n",
        "    W1, b1, W2, b2 = theta\n",
        "    x = np.array(x)\n",
        "    x = x[:, np.newaxis]\n",
        "\n",
        "    z1 = np.dot(W1, x) + b1  \n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(W2, a1) + b2\n",
        "\n",
        "    return z2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La funcion obejtivo que buscamos minimizar, sabemos que está dada por: \n",
        "$\\newline L = \\frac{1}{2}(f_{\\theta_{t}}(\\mathrm{\\mathbf{x}}_{i}) - y_{i})^2$\n",
        "\n",
        "Para calcular el gradiente de forma numércia, vamos a usar la estrategia propuesta por la cátedra para calcular las derivadas parciales. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "P-R0FjEzvhgn"
      },
      "outputs": [],
      "source": [
        "#Calculo del gradiente numerico\n",
        "\n",
        "def funcion_objetivo(theta, x, y):\n",
        "    print(f'theta: {theta}')\n",
        "    loss = 0.5 * (forward(theta, x) - y)**2\n",
        "    return loss\n",
        "\n",
        "def numerical_gradient(theta, x, y, eps):\n",
        "    epsilon = eps  # Pequeña cantidad para el cálculo numérico del gradiente\n",
        "    gradiente = [np.zeros_like(param) for param in theta]\n",
        "\n",
        "    for i in range(len(theta)):\n",
        "        # Crear copias independientes de theta_plus y theta_minus\n",
        "        theta_plus = np.array(np.copy(theta))\n",
        "        theta_minus = np.array(np.copy(theta))\n",
        "    \n",
        "        # Aumentar y disminuir un poco el parámetro actual para calcular el gradiente\n",
        "        theta_plus[i] += epsilon\n",
        "        theta_minus[i] -= epsilon\n",
        "        print(f'theta_plus: {theta_plus}')\n",
        "        print(f'theta_minus: {theta_minus}')\n",
        "\n",
        "        # Calcular las pérdidas para los parámetros aumentados y disminuidos\n",
        "        loss_plus = funcion_objetivo(theta_plus, x, y)\n",
        "        loss_minus = funcion_objetivo(theta_minus, x, y)\n",
        "\n",
        "        # Calcular el gradiente parcial utilizando las derivadas parciales\n",
        "        gradiente[i] = (loss_plus - loss_minus) / (2 * epsilon)\n",
        "\n",
        "    gradiente = np.array(gradiente)\n",
        "\n",
        "    return gradiente\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "rJRtIYxMvhgo"
      },
      "outputs": [],
      "source": [
        "#funcion fit y loop de entrenamiento\n",
        "def fit(theta, x, y, learning_rate=0.001, epochs=1000):\n",
        "    TOLERANCIA = 0.0001\n",
        "    eps = 1e-1\n",
        "    loss_accum = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        loss_epoch = 0.0  # Pérdida acumulada en el epoch actual\n",
        "\n",
        "        for i in range(len(x)):\n",
        "            # Obtener el vector x y la salida esperada y correspondientes\n",
        "            x_i = x[i]\n",
        "            y_i = y[i]\n",
        "\n",
        "            # Calcular el gradiente numérico para el ejemplo actual\n",
        "            gradient = numerical_gradient(theta, x_i, y_i, eps)\n",
        "    \n",
        "            print(f'gradiente: {gradient}, theta: {theta}')\n",
        "\n",
        "            # Actualizar los parámetros\n",
        "            theta -= learning_rate * gradient\n",
        "\n",
        "            # Calcular la pérdida para el ejemplo actual\n",
        "            loss_i = funcion_objetivo(theta, x_i, y_i)\n",
        "            loss_epoch += loss_i\n",
        "\n",
        "        # Calcular la pérdida promedio para el epoch actual\n",
        "        loss_avg = loss_epoch / len(x)\n",
        "        loss_accum.append(loss_avg)\n",
        "\n",
        "        if abs(theta - loss_avg) < TOLERANCIA:\n",
        "            break\n",
        "\n",
        "    return loss_accum, theta\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "IS4sKd_Hvhgo"
      },
      "outputs": [],
      "source": [
        "def predict(x, theta):\n",
        "        y = np.dot(x, theta)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "theta_plus: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n",
            "theta_minus: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n",
            "theta: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n",
            "theta: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n",
            "theta_plus: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n",
            "theta_minus: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n",
            "theta: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n",
            "theta: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n",
            "theta_plus: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n",
            "theta_minus: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n",
            "theta: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n",
            "theta: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n",
            "theta_plus: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n",
            "theta_minus: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n",
            "theta: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n",
            "theta: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n",
            "gradiente: [[[0.]]\n",
            "\n",
            " [[0.]]\n",
            "\n",
            " [[0.]]\n",
            "\n",
            " [[0.]]], theta: [array([[0.87042279, 0.32430587, 0.21274525, 0.68317046, 0.82073688,\n",
            "         0.41763618],\n",
            "        [0.89249721, 0.22039439, 0.8341225 , 0.04978126, 0.57075423,\n",
            "         0.94614074],\n",
            "        [0.98854873, 0.38136489, 0.65550829, 0.51858125, 0.31052127,\n",
            "         0.74015276],\n",
            "        [0.91538638, 0.2058532 , 0.16920507, 0.5432499 , 0.80571925,\n",
            "         0.33677357],\n",
            "        [0.53106099, 0.24648787, 0.42937119, 0.55128718, 0.06002364,\n",
            "         0.96753509]])\n",
            " array([[0.9826956 ],\n",
            "        [0.61303429],\n",
            "        [0.09561553],\n",
            "        [0.00664816],\n",
            "        [0.91244399]])\n",
            " array([[0.37263231, 0.9865202 , 0.83292144, 0.85717883, 0.63060507]])\n",
            " array([[0.1346366]])]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "non-broadcastable output operand with shape (4,) doesn't match the broadcast shape (4,1,4)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/5d/4g206gss6cg3fktfbycqnb540000gn/T/ipykernel_27631/1303780019.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mloss_accum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Obtener predicciones en el conjunto de datos de prueba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/var/folders/5d/4g206gss6cg3fktfbycqnb540000gn/T/ipykernel_27631/2101618221.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(theta, x, y, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# Actualizar los parámetros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mtheta\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Calcular la pérdida para el ejemplo actual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (4,) doesn't match the broadcast shape (4,1,4)"
          ]
        }
      ],
      "source": [
        "# Entrenar la red neuronal\n",
        "df_test = pd.read_excel(\"datos.xlsx\", nrows=10)\n",
        "x = df_test.iloc[:, 1:7].values.tolist()\n",
        "y = df_test.iloc[:, 7].values.tolist()\n",
        "\n",
        "\n",
        "loss_accum, theta_new = fit(theta, x, y, learning_rate=0.001, epochs=1000)\n",
        "\n",
        "# Obtener predicciones en el conjunto de datos de prueba\n",
        "y_pred = predict(x, theta_new)\n",
        "\n",
        "# Calcular el error cuadrático medio en el conjunto de datos de prueba\n",
        "mse = ((y_pred - y) ** 2).mean()\n",
        "\n",
        "# Graficar la función objetivo a lo largo del entrenamiento\n",
        "plt.plot(loss_accum)\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Función Objetivo')\n",
        "plt.title('Evolución de la función objetivo durante el entrenamiento')\n",
        "plt.show()\n",
        "\n",
        "# Graficar el error cuadrático medio en el conjunto de datos de prueba\n",
        "plt.scatter(y, y_pred)\n",
        "plt.xlabel('Valor Real')\n",
        "plt.ylabel('Predicción')\n",
        "plt.title('Predicciones vs. Valores Reales en el conjunto de datos de prueba')\n",
        "plt.show()\n",
        "\n",
        "print(f'Error cuadrático medio en el conjunto de datos de prueba: {mse}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
